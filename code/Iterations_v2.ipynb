{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-20T19:24:33.602654Z",
     "start_time": "2024-03-20T19:24:33.588945Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as sps\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from libmf import mf"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def usefulness(c, w, noice):\n",
    "    return np.arctan(c - w + noice) / np.pi + 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T19:22:20.546404Z",
     "start_time": "2024-03-20T19:22:20.538840Z"
    }
   },
   "id": "55dfca8f998a51a5",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "customer_distribution = sps.norm(0.6, 0.2)\n",
    "w_distribution = sps.norm(0, 0.4)\n",
    "\n",
    "epsilon = sps.norm(0, 0.05)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T19:22:21.701071Z",
     "start_time": "2024-03-20T19:22:21.675875Z"
    }
   },
   "id": "70b1cac38b3c3832",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def interpol_distribution(sample):\n",
    "    hst = np.histogram(sample, density=True, bins=200)\n",
    "    return interp1d(hst[1][:-1], hst[0], kind='linear',\n",
    "                               fill_value=0.0, bounds_error=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T19:22:24.994387Z",
     "start_time": "2024-03-20T19:22:24.984205Z"
    }
   },
   "id": "33d403b6405cea84",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def zero_step(model: CMFRecommender, user_info, item_info, topn=52):\n",
    "    new_feedback = []\n",
    "\n",
    "    maximal_user, maximal_item = model.get_max_index()\n",
    "    old_users = model.get_users().set_index(\"UserId\")\n",
    "    \n",
    "    for i in range(topn):\n",
    "        user_id = np.random.choice(round(maximal_user) - 1)\n",
    "        for index, item_row in item_info.iterrows():\n",
    "            deal = sps.bernoulli.rvs(usefulness(old_users.loc[user_id], item_row[\"F\"], epsilon.rvs()))  # моделируем сделки\n",
    "            new_feedback.append((user_id, item_row[\"ItemId\"], deal))\n",
    "    \n",
    "    for index, user_row in user_info.iterrows():\n",
    "        w_offered = model.recommend_items_cold(user_row[\"F\"], topn)[\"ItemId\"]\n",
    "        for w in w_offered:\n",
    "            deal = sps.bernoulli.rvs(usefulness(user_row[\"F\"], w, epsilon.rvs()))  # моделируем сделки\n",
    "            new_feedback.append((user_row[\"UserId\"], w, deal))\n",
    "    \n",
    "    model.retrain(new_feedback, user_info, item_info)\n",
    "    return model, new_feedback\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T19:41:34.082294Z",
     "start_time": "2024-03-20T19:41:34.064677Z"
    }
   },
   "id": "15c9afdeb2e5f9a5",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CMFRecommender' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdynamic_system_iterate\u001B[39m(model: \u001B[43mCMFRecommender\u001B[49m, customer_distribution, w_distribution, c_size, w_size, num_of_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m,\n\u001B[1;32m      2\u001B[0m                            topn\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m      4\u001B[0m     maximal_user, maximal_item \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mget_max_index()\n\u001B[1;32m      5\u001B[0m     user_info \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF\u001B[39m\u001B[38;5;124m\"\u001B[39m: customer_distribution\u001B[38;5;241m.\u001B[39mrvs(size\u001B[38;5;241m=\u001B[39mc_size)})  \u001B[38;5;66;03m# size = (c_size, c_feature_size) в многомерном случае \u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'CMFRecommender' is not defined"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T15:52:22.365987Z",
     "start_time": "2024-03-20T15:52:22.000523Z"
    }
   },
   "id": "ebd805e2fa269c00",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cmfrec import CMF_implicit\n",
    "\n",
    "\n",
    "\n",
    "class CMFRecommender:\n",
    "    def __init__(self, num_of_factors=40):\n",
    "        self.model = CMF_implicit(k=num_of_factors)\n",
    "        self.ratings = None\n",
    "        self.trained = False\n",
    "        self.user_info = None\n",
    "        self.item_info = None\n",
    "\n",
    "    def get_users(self):\n",
    "        return self.user_info\n",
    "\n",
    "    def fit(self, ratings, user_info, item_info):\n",
    "        self.trained = True\n",
    "        self.ratings = ratings\n",
    "        self.user_info = user_info\n",
    "        self.item_info = item_info\n",
    "        self.model.fit(X=ratings, U=user_info, I=item_info)\n",
    "\n",
    "    def get_interacted_items(self, user_id):\n",
    "        return self.ratings.loc[self.ratings.UserId == user_id]['ItemId'].unique()\n",
    "\n",
    "    def get_unqiue_item_count(self):\n",
    "        return len(self.ratings[\"ItemId\"].unique())\n",
    "\n",
    "    def recommend_items_new(self, user_id, I, topn):\n",
    "        recommended_items = self.model.topN_new(user=user_id, n=topn, output_score=True)[:2]\n",
    "        return pd.DataFrame({\"ItemId\": recommended_items[0], \"Rating\": recommended_items[1]})\n",
    "\n",
    "    def recommend_items_cold(self, user_row, topn=10):\n",
    "        n = min(topn, self.get_unqiue_item_count())\n",
    "        recommended_items = self.model.topN_cold(U=user_row, n=n, output_score=True)[:2]\n",
    "        return pd.DataFrame({\"ItemId\": recommended_items[0], \"Rating\": recommended_items[1]})\n",
    "\n",
    "    def get_max_index(self):\n",
    "        return self.ratings[\"UserId\"].max(), self.ratings[\"ItemId\"].max()\n",
    "\n",
    "    def recommend_items(self, user_id=None, topn=10, exclude_rated=True):\n",
    "        items_to_ignore = []\n",
    "        if exclude_rated:\n",
    "            items_to_ignore.extend(self.get_interacted_items(user_id))\n",
    "        n = min(topn, self.get_unqiue_item_count() - len(items_to_ignore))\n",
    "\n",
    "        recommended_items = self.model.topN(user=user_id, n=n, output_score=True)[:2]\n",
    "\n",
    "        return pd.DataFrame({\"ItemId\": recommended_items[0], \"Rating\": recommended_items[1]})\n",
    "\n",
    "    def retrain(self, new_ratings, new_users, new_items):\n",
    "        number_of_new_ratings = len(new_ratings)\n",
    "        new_ratings = pd.DataFrame(new_ratings, columns =['UserId', 'ItemId', 'Rating'])\n",
    "        if self.ratings is None:\n",
    "            self.ratings = new_ratings\n",
    "        else:\n",
    "            self.ratings = pd.concat([self.ratings.loc[number_of_new_ratings:], new_ratings], ignore_index=True)\n",
    "        self.user_info = pd.concat([self.user_info, new_users])\n",
    "        self.item_info = pd.concat([self.item_info, new_items])\n",
    "\n",
    "        self.fit(ratings=self.ratings, user_info=self.user_info, item_info=self.item_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T19:43:33.236642Z",
     "start_time": "2024-03-20T19:43:33.217440Z"
    }
   },
   "id": "513d2cbef0f50f2f",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def dynamic_system_iterate(model: CMFRecommender, customer_distribution, w_distribution, c_size=10, w_size=10, num_of_steps=5,\n",
    "                           topn=5, delta=1):\n",
    "    \n",
    "    maximal_user, maximal_item = model.get_max_index()\n",
    "    user_info = pd.DataFrame({\"F\": customer_distribution.rvs(size=c_size)})  # size = (c_size, c_feature_size) в многомерном случае \n",
    "    user_info[\"UserId\"] = np.arange(maximal_user + 1, maximal_user + 1  + c_size)\n",
    "\n",
    "    item_info = pd.DataFrame({\"F\": w_distribution.rvs(size=w_size)})  # size = (w_size, w_feature_size) в многомерном случае \n",
    "    item_info[\"ItemId\"] = np.arange(maximal_item + 1, maximal_item + 1 + w_size)\n",
    "    model, new_feedback = zero_step(model, user_info, item_info, topn=topn)\n",
    "    \n",
    "    for step in range(1, num_of_steps + 1):\n",
    "        for index, user_row in user_info.iterrows():\n",
    "            items_interacted = model.get_interacted_items(user_row[\"UserId\"])\n",
    "            w_offered = model.recommend_items(user_row[\"UserId\"], topn=topn)[\"ItemId\"]\n",
    "            # w_offered = model.recommend_items(user_row[\"UserId\"], topn=topn, include=np.setdiff1d(item_info[\"ItemId\"], items_interacted))[\"ItemId\"]\n",
    "            for w in w_offered:\n",
    "                deal = sps.bernoulli.rvs(usefulness(user_row[\"F\"], w, epsilon.rvs()))  # моделируем сделки\n",
    "                new_feedback.append((user_row[\"UserId\"], w, deal))\n",
    "        model.retrain(new_feedback, pd.DataFrame(), pd.DataFrame())\n",
    "    \n",
    "    \n",
    "    # смена распределения\n",
    "    new_feedback_df = pd.DataFrame(new_feedback, columns=['UserId', 'ItemId', 'Feedback'])\n",
    "    grouped_users = new_feedback_df.groupby('UserId')['Feedback'].mean().reset_index()\n",
    "    # probabilities_users = grouped_users['Feedback'] / grouped_users['Feedback'].sum()\n",
    "    user_info.set_index('UserId', inplace=True)\n",
    "    customer_distribution = sps.gaussian_kde(user_info.loc[grouped_users['UserId']], grouped_users['Feedback'])\n",
    "    grouped_items = new_feedback_df.groupby('ItemId')['Feedback'].mean().reset_index()\n",
    "    # probabilities_items = grouped_items['ItemId'] / grouped_items['ItemId'].sum()\n",
    "    grouped_items['Feedback'] += delta\n",
    "    item_info.set_index('ItemId', inplace=True)\n",
    "    w_distribution = sps.gaussian_kde(item_info.loc[grouped_users['ItemId']], grouped_items['Feedback'])\n",
    "\n",
    "    return customer_distribution, w_distribution, new_feedback, model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T19:54:07.686348Z",
     "start_time": "2024-03-20T19:54:07.669876Z"
    }
   },
   "id": "4c86e4614c7d846e",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "user_info = pd.DataFrame({\"F\": customer_distribution.rvs(size=100)}) # генерим датасет для нулевой итерации\n",
    "user_info[\"UserId\"] = np.arange(100)\n",
    "\n",
    "item_info = pd.DataFrame({\"F\": w_distribution.rvs(size=100)})\n",
    "item_info[\"ItemId\"] = np.arange(100)\n",
    "feedback = []\n",
    "\n",
    "for i, user_row in user_info.iterrows():\n",
    "    for j, item_row in item_info.iterrows():\n",
    "        deal = sps.bernoulli.rvs(usefulness(user_row[\"F\"], item_row[\"F\"], epsilon.rvs()))\n",
    "        feedback.append((user_row[\"UserId\"], item_row[\"ItemId\"], deal))\n",
    "\n",
    "model = CMFRecommender()            \n",
    "model.retrain(feedback, user_info, item_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T19:50:19.544624Z",
     "start_time": "2024-03-20T19:50:16.785372Z"
    }
   },
   "id": "5144e4c9f8cb8f53",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of dimensions is greater than number of samples. This results in a singular data covariance matrix, which cannot be treated using the algorithms implemented in `gaussian_kde`. Note that `gaussian_kde` interprets each *column* of `dataset` to be a point; consider transposing the input to `dataset`.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[61], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdynamic_system_iterate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustomer_distribution\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw_distribution\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[59], line 30\u001B[0m, in \u001B[0;36mdynamic_system_iterate\u001B[0;34m(model, customer_distribution, w_distribution, c_size, w_size, num_of_steps, topn, delta)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# probabilities_users = grouped_users['Feedback'] / grouped_users['Feedback'].sum()\u001B[39;00m\n\u001B[1;32m     29\u001B[0m user_info\u001B[38;5;241m.\u001B[39mset_index(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUserId\u001B[39m\u001B[38;5;124m'\u001B[39m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 30\u001B[0m customer_distribution \u001B[38;5;241m=\u001B[39m \u001B[43msps\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgaussian_kde\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_info\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mgrouped_users\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mUserId\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrouped_users\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mFeedback\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m grouped_items \u001B[38;5;241m=\u001B[39m new_feedback_df\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mItemId\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFeedback\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmean()\u001B[38;5;241m.\u001B[39mreset_index()\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# probabilities_items = grouped_items['ItemId'] / grouped_items['ItemId'].sum()\u001B[39;00m\n",
      "File \u001B[0;32m~/2024-Project-144/code/venv/lib/python3.10/site-packages/scipy/stats/_kde.py:223\u001B[0m, in \u001B[0;36mgaussian_kde.__init__\u001B[0;34m(self, dataset, bw_method, weights)\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn:\n\u001B[1;32m    217\u001B[0m     msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of dimensions is greater than number of samples. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    218\u001B[0m            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis results in a singular data covariance matrix, which \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    219\u001B[0m            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot be treated using the algorithms implemented in \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    220\u001B[0m            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`gaussian_kde`. Note that `gaussian_kde` interprets each \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    221\u001B[0m            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*column* of `dataset` to be a point; consider transposing \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    222\u001B[0m            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe input to `dataset`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 223\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[1;32m    225\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    226\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_bandwidth(bw_method\u001B[38;5;241m=\u001B[39mbw_method)\n",
      "\u001B[0;31mValueError\u001B[0m: Number of dimensions is greater than number of samples. This results in a singular data covariance matrix, which cannot be treated using the algorithms implemented in `gaussian_kde`. Note that `gaussian_kde` interprets each *column* of `dataset` to be a point; consider transposing the input to `dataset`."
     ]
    }
   ],
   "source": [
    "dynamic_system_iterate(model, customer_distribution, w_distribution)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T19:50:24.073376Z",
     "start_time": "2024-03-20T19:50:21.135393Z"
    }
   },
   "id": "993fb963881b2f8e",
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e0a9608907e22999"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
